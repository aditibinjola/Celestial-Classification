# -*- coding: utf-8 -*-
"""ads project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZUInX0Ri0LFAU3xZw0_L0RwuDB7dkiYQ

# Environment Sanity Check #

Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.

You can check the output of `!nvidia-smi` to check which GPU you have.  Please uncomment the cell below if you'd like to do that.  Currently, RAPIDS runs on all available Colab GPU instances.
"""

# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.
# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.
!git clone https://github.com/rapidsai/rapidsai-csp-utils.git
!python rapidsai-csp-utils/colab/pip-install.py

from google.colab import drive
drive.mount('/content/drive')

import cuml

import cupy as cp
import cudf as cd
import pandas as pd
import numpy as np

# data= cd.read_csv("/content/drive/MyDrive/Classroom/UCS622: Conversational AI: Accelerated Data Science [Advanced]/star_classification.csv")
data= cd.read_csv("/content/SkyServerDataset.csv")

data.head()

data.info()

data = data.drop(['obj_ID'],axis=1)
data = data.drop(['rerun_ID'],axis=1)
data.drop_duplicates()
data

data.isnull().sum()

cols = ['run_ID', 'ra', 'dec']

# Convert columns to numeric, coercing errors to NaN
for col in cols:
    data[col] = data[col].astype('float64').fillna(-1)

# Fill NaN values with mean, median, and std respectively
data['run_ID'] = data['run_ID'].replace(-1, data['run_ID'].mean())
data['ra'] = data['ra'].replace(-1, data['ra'].median())
data['dec'] = data['dec'].replace(-1, data['dec'].std())

data

data.isnull().sum()

data = data.drop(columns=['spec_obj_ID'])

data.info()

import matplotlib.pyplot as plt
pdf = data.to_pandas()

pdf

import seaborn as sns
sns.boxplot(pdf,orient='h')

sns.boxplot(pdf['r'])

pdf.iloc[:,:-1]

# Assuming 'data' is your DataFrame
# data_without_class = pdf.drop('class', axis=1)

from scipy import stats
#Removing outliers Z-score
z_threshold=3

z_scores = np.abs(stats.zscore(pdf.iloc[:, pdf.columns != 'class']))

# Create a mask to identify outliers
outlier_mask = (z_scores > z_threshold).any(axis=1)
outlier_mask

# Remove rows with outliers
df_no_outliers = pdf[~outlier_mask]

# Display the DataFrame with outliers removed
print(df_no_outliers)

df_no_outliers.head()

from matplotlib import pyplot as plt
import seaborn as sns
pdf.groupby('class').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

sns.scatterplot(x = df_no_outliers.ra, y = df_no_outliers.dec)
plt.show()

df_no_outliers.hist(bins =25 , figsize= (14,14))
plt.show()

data_no_outliers=cd.DataFrame.from_pandas(df_no_outliers)
from cuml import preprocessing
LE = preprocessing.LabelEncoder()
data_no_outliers['class'] = LE.fit_transform(data_no_outliers['class'])

distinct= data_no_outliers['class'].value_counts()
distinct

X = data_no_outliers[['u', 'g', 'r', 'i', 'z', 'redshift', 'plate']]
X

y = data_no_outliers['class']
y

"""RESAMPLING"""

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state = 30, k_neighbors = 5)
X_res, y_res = sm.fit_resample(X.to_pandas(), y.to_pandas())

"""Preprocessing using StandardScaler()"""

ss=preprocessing.StandardScaler()
X_res=ss.fit_transform(X_res)
X_res=cd.DataFrame.from_pandas(X_res)
X_res.head()

y_res.value_counts()

y_res=cd.Series.from_pandas(y_res)

import cuml
from cuml import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.25, random_state = 30)

"""Algorithms"""

# Creating the dataframe in which we'll store the accuracy scores of all the classification algorithms so we can choose the best one.
acc_score = cd.DataFrame(columns=['Algorithm', 'cuml_accuracy', 'cuml_r2_score'])

acc_score

"""1. Logistic Regression Model"""

from cuml import make_regression
from cuml.linear_model import LogisticRegression as cuLogisticRegression
from cuml.metrics.regression import r2_score
from sklearn.linear_model import LogisticRegression as skLogsiticRegression

model = cuLogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
y_pred1 = model.predict(X_test)

from sklearn.metrics import accuracy_score
from cupy import asnumpy
cu_score = cuml.metrics.accuracy_score( y_test, y_pred1 )
y_test_float32 = y_test.astype('float32')
cu_r2_1= cuml.metrics.r2_score( y_test_float32, y_pred1)

new_row = cd.DataFrame({'Algorithm': ['LogisticRegression'],
                          'cuml_accuracy': [cu_score],
                          'cuml_r2_score': [cu_r2_1]})
acc_score = cd.concat([acc_score, new_row], ignore_index=True)
print(acc_score)

from cuml.metrics import confusion_matrix
y_test_int32 = y_test.astype('int32')
y_pred_lr_int32 = y_pred1.astype('int32')

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test_int32, y_pred_lr_int32)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_.to_pandas())
disp.plot()

"""2. KNN"""

knn_df = cd.DataFrame(columns=['Neighbors','CumlScore'])

import cuml
from cuml.neighbors import KNeighborsClassifier

# Assuming X_train, X_test, y_train are cuDF DataFrames
# Convert cuDF DataFrames to cuML DataFrames
X_train_cuml = cd.DataFrame.from_pandas(X_train)
X_test_cuml = cd.DataFrame.from_pandas(X_test)
y_train_cuml = cd.Series(y_train)

for i in range(1, 21):
    model = KNeighborsClassifier(n_neighbors=i)

    model.fit(X_train_cuml, y_train_cuml)
    y_pred2 = model.predict(X_test_cuml)
    knn_newrow= cd.DataFrame({'Neighbors':i, 'CumlScore':cuml.metrics.accuracy_score( y_test, y_pred2),},index=[1])
    knn_df = cd.concat([knn_df, knn_newrow])
knn_df

knn_df = knn_df.sort_values(by='CumlScore', ascending = False)
knn_df.head()

from cuml.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors = 3)
model.fit(X_train_cuml, y_train_cuml)
y_pred2 = model.predict(X_test_cuml)

from sklearn.metrics import accuracy_score
from cupy import asnumpy
cu_score_knn = cuml.metrics.accuracy_score( y_test, y_pred2)
y_test_float32 = y_test.astype('float32')
cu_r2_knn= cuml.metrics.r2_score( y_test_float32, y_pred2)

new_row1 = cd.DataFrame({'Algorithm': ['KNN'],
                          'cuml_accuracy': [cu_score_knn],
                          'cuml_r2_score': [cu_r2_knn]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32 = y_test.astype('int32')
y_pred2_int32 = y_pred2.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix = cucm(y_test_int32, y_pred2_int32)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_.to_pandas())
disp.plot()

"""3. SVM Classifier"""

from cuml.svm import SVC
model_svc=SVC()
model_svc.fit(X_train_cuml, y_train_cuml)
y_pred_svc=model_svc.predict(X_test_cuml)

cu_score_svc = cuml.metrics.accuracy_score( y_test, y_pred_svc)
y_test_float32 = y_test.astype('float32')
cu_r2_svc= cuml.metrics.r2_score( y_test_float32, y_pred_svc)

new_row1 = cd.DataFrame({'Algorithm': ['SVM'],
                          'cuml_accuracy': [cu_score_svc],
                          'cuml_r2_score': [cu_r2_svc]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32 = y_test.astype('int32')
y_pred_svc_int32 = y_pred_svc.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix = cucm(y_test_int32, y_pred_svc_int32)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_.to_pandas())
disp.plot()

"""4. XGBoost"""

import xgboost as xgb
model = xgb.XGBClassifier(random_state = 30,device='cuda')
model.fit(X_train.to_pandas(), y_train.to_pandas())
y_pred6 = model.predict(X_test.to_pandas())

cu_score_xg=cuml.metrics.accuracy_score(y_test.to_pandas(),y_pred6)
y_test_float32 = y_test.astype('float32')
cu_r2_xg= cuml.metrics.r2_score( y_test_float32, y_pred6)

new_row1 = cd.DataFrame({'Algorithm': ['XGBoost'],
                          'cuml_accuracy': [cu_score_xg],
                          'cuml_r2_score': [cu_r2_xg]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32_xg = y_test.astype('int32')
y_pred_int32_xg = y_pred6.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix_xg = cucm(y_test_int32_xg, y_pred_int32_xg)
disp_xg = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_)
disp_xg.plot()

"""5. ANN"""

from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical

# Create the neural network model
model = Sequential()
model.add(Dense(128, input_dim=X_train_cuml.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Assuming y_train is your training labels
num_classes = len(np.unique(y_train))

import os
import numpy as np
import tensorflow as tf
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # Assuming you want to use GPU device 0

from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical

# Assuming X_train_cuml and y_train are your training data and labels respectively
# Convert cuDF or cuML GPU arrays to NumPy arrays
X_train_numpy = X_train_cuml.to_numpy()
y_train_numpy = y_train.to_numpy()

# Check if GPU is available
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# Create the neural network model
model = Sequential()
model.add(Dense(128, input_dim=X_train_numpy.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))
# Modify this layer to match the number of classes in your classification problem
model.add(Dense(num_classes, activation='softmax'))  # Assuming num_classes is the number of output classes

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Assuming y_train is your training labels
# Convert labels to one-hot encoding
y_train_one_hot = to_categorical(y_train_numpy)

# Train the model
model.fit(X_train_numpy, y_train_one_hot, epochs=10, batch_size=32)

# Once the model is trained, you can use it for prediction
# For prediction, you need to ensure that your input data is in the same format as your training data
# Assuming X_test_cuml is your test data
# Convert test data to NumPy array if necessary
# X_test_numpy = X_test_cuml.to_numpy()
# y_pred = model.predict(X_test_numpy)

X_test_numpy = X_test.to_numpy()
y_pred_ann= model.predict(X_test_numpy)

y_pred_classes = y_pred_ann.argmax(axis=-1)
y_pred_classes

cu_score_ann =cuml.metrics.accuracy_score(y_test.to_numpy(),y_pred_classes)
y_test_float32 = y_test.astype('float32')
cu_r2_ann= cuml.metrics.r2_score( y_test_float32, y_pred_classes)

new_row1 = cd.DataFrame({'Algorithm': ['ANN'],
                          'cuml_accuracy': [cu_score_ann],
                          'cuml_r2_score': [cu_r2_ann]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32 = y_test.astype('int32')
y_pred_int32 = y_pred_classes.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix = cucm(y_test_int32, y_pred_int32)
# disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
# display_labels=model.classes_.to_pandas())
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get())
disp.plot()

"""6. Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier(random_state = 30)
model.fit(X_train.to_pandas(), y_train.to_pandas())
y_pred_dt = model.predict(X_test.to_pandas())

cu_score_dt=cuml.metrics.accuracy_score(y_test.to_pandas(),y_pred_dt)
y_test_float32 = y_test.astype('float32')
cu_r2_dt= cuml.metrics.r2_score( y_test_float32, y_pred_dt)

new_row1 = cd.DataFrame({'Algorithm': ['Decision Tree'],
                          'cuml_accuracy': [cu_score_dt],
                          'cuml_r2_score': [cu_r2_dt]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32 = y_test.astype('int32')
y_pred_int32 = y_pred_dt.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix = cucm(y_test_int32, y_pred_int32)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_)

disp.plot()

"""7. Gaussian Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train.to_pandas(), y_train.to_pandas())
y_pred_nb = model.predict(X_test.to_pandas())

cu_score_nb= cuml.metrics.accuracy_score(y_test.to_pandas(),y_pred_nb)
y_test_float32 = y_test.astype('float32')
cu_r2_nb= cuml.metrics.r2_score( y_test_float32, y_pred_nb )

new_row1 = cd.DataFrame({'Algorithm': ['Gaussian Naive Bayes'],
                          'cuml_accuracy': [cu_score_nb],
                          'cuml_r2_score': [cu_r2_nb]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32 = y_test.astype('int32')
y_pred_int32 = y_pred_nb.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix = cucm(y_test_int32, y_pred_int32)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_)

disp.plot()

"""8. Random Forest"""

rf_df = cd.DataFrame(columns=['Estimators','Accuracy'])
from cuml.ensemble import RandomForestClassifier as cuRF
for i in range(1,21):
    model = cuRF(n_estimators = i, random_state = 30)
    model.fit(X_train_cuml, y_train_cuml)
    y_pred_rf = model.predict(X_test_cuml)
    rf_newrow=cd.DataFrame({'Estimators':i, 'Accuracy':cuml.metrics.accuracy_score(y_test,y_pred_rf)},index=[1])
    rf_df = cd.concat([rf_df,rf_newrow])

rf_df

rf_df = rf_df.sort_values(by='Accuracy', ascending = False)
rf_df=  rf_df.head(1)
rf_df

import cudf
from cuml.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X_cudf = cudf.DataFrame(X_train)
y_cudf = cudf.Series(y_train)

rf_model = RandomForestClassifier(n_estimators=17, max_depth=10, random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

cu_score_rf= cuml.metrics.accuracy_score(y_test.to_pandas(),y_pred_rf)
y_test_float32 = y_test.astype('float32')
cu_r2_rf = cuml.metrics.r2_score( y_test_float32, y_pred_rf )

new_row1 = cd.DataFrame({'Algorithm': ['Random Forest'],
                          'cuml_accuracy': [cu_score_rf],
                          'cuml_r2_score': [cu_r2_rf]})
acc_score = cd.concat([acc_score, new_row1], ignore_index=True)
print(acc_score)

y_test_int32 = y_test.astype('int32')
y_pred_int32 = y_pred_rf.astype('int32')
from cuml.metrics import confusion_matrix as cucm
# Compute confusion matrix
conf_matrix = cucm(y_test_int32, y_pred_int32)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix.get(),
display_labels=model.classes_.to_pandas())

disp.plot()

"""Results"""

Ascore_df = acc_score.sort_values(by = 'cuml_accuracy', ascending = False)
Ascore_df

Rscore_df = acc_score.sort_values(by = 'cuml_r2_score', ascending = False)
Rscore_df

#So according to both the parameters: XGBOOST IS TOP PERFORMING MODEL

"""Data Visualisation"""

from sklearn.metrics import confusion_matrix
conf_matrix = cucm(y_test_int32_xg, y_pred_int32_xg)
class_names=['GALAXY','QSO','STAR']

# Plot confusion matrix as a heatmap
plt.figure(figsize=(4,3))
sns.heatmap(conf_matrix.get(), annot=True, fmt="d", cmap="Blues", cbar=False,xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix")
plt.xlabel("Predicted labels")
plt.ylabel("True labels")
plt.show()

acc_score.to_pandas().plot(x="Algorithm", y="cuml_accuracy", kind="bar")

acc_score.to_pandas().plot(x="Algorithm", y="cuml_r2_score", kind="bar")

